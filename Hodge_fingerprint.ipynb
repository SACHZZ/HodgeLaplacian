{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hodge_fingerprint.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMck2sLy6COGVsdfglEGA0U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SACHZZ/HodgeLaplacian/blob/main/Hodge_fingerprint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "path=\"/content/drive/My Drive/Colab Notebooks/TDA/NTU_Projects/Hodge_Laplacian\"\n",
        "os.chdir(path)"
      ],
      "metadata": {
        "id": "zGjxgaED-q0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGdOeyRyJwS_"
      },
      "outputs": [],
      "source": [
        "!pip install GeneralisedFormanRicci\n",
        "!pip install gudhi\n",
        "!pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import gudhi as gd\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "import math\n",
        "import matplotlib as mpl\n",
        "import plotly.io as pio\n",
        "import matplotlib.pyplot as plt\n",
        "from GeneralisedFormanRicci.frc import gen_graph\n",
        "from scipy.sparse import *\n",
        "from scipy import *"
      ],
      "metadata": {
        "id": "bsRxSiJpJ6it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def faces(simplices):\n",
        "    faceset = set()\n",
        "    for simplex in simplices:\n",
        "        numnodes = len(simplex)\n",
        "        for r in range(numnodes, 0, -1):\n",
        "            for face in combinations(simplex, r):\n",
        "                faceset.add(tuple(sorted(face)))\n",
        "    return faceset\n",
        "\n",
        "def n_faces(face_set, n):\n",
        "    return filter(lambda face: len(face)==n+1, face_set)\n",
        "\n",
        "def boundary_operator(face_set, i):\n",
        "    source_simplices = list(n_faces(face_set, i))\n",
        "    target_simplices = list(n_faces(face_set, i-1))\n",
        "    #print(source_simplices, target_simplices)\n",
        "\n",
        "    if len(target_simplices)==0:\n",
        "        S = dok_matrix((1, len(source_simplices)), dtype=np.float64)\n",
        "        S[0, 0:len(source_simplices)] = 1\n",
        "    else:\n",
        "        source_simplices_dict = {source_simplices[j]: j for j in range(len(source_simplices))}\n",
        "        target_simplices_dict = {target_simplices[i]: i for i in range(len(target_simplices))}\n",
        "\n",
        "        S = dok_matrix((len(target_simplices), len(source_simplices)), dtype=np.float64)\n",
        "        for source_simplex in source_simplices:\n",
        "            for a in range(len(source_simplex)):\n",
        "                target_simplex = source_simplex[:a]+source_simplex[(a+1):]\n",
        "                i = target_simplices_dict[target_simplex]\n",
        "                j = source_simplices_dict[source_simplex]\n",
        "                S[i, j] = -1 if a % 2==1 else 1\n",
        "    \n",
        "    return S"
      ],
      "metadata": {
        "id": "IlrCqANrJ8UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "xyz_files = []\n",
        "for x in os.listdir():\n",
        "    if x.endswith(\".xyz\"):\n",
        "        xyz_files.append(x)"
      ],
      "metadata": {
        "id": "vVBXz2wOJ-h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size(xyz_files)"
      ],
      "metadata": {
        "id": "u2u3O1JPteAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "veca = []\n",
        "for filename in xyz_files:\n",
        "    vec = [filename]\n",
        "    atoms = []\n",
        "    coords = []\n",
        "\n",
        "    xyz = open(filename)\n",
        "    n_atoms = int(xyz.readline())\n",
        "    title = xyz.readline()\n",
        "    for line in xyz:\n",
        "        atom,x,y,z = line.split()\n",
        "        atoms.append(atom)\n",
        "        coords.append([float(x), float(y), float(z)])\n",
        "    xyz.close()\n",
        "    \n",
        "    \n",
        "    for f in np.arange(0,9,0.5):\n",
        "        rc = gd.RipsComplex(coords, max_edge_length=f)\n",
        "        simplex_tree = rc.create_simplex_tree(max_dimension=2)\n",
        "        val = simplex_tree.get_filtration()\n",
        "        simplices = set()\n",
        "        for v in val:\n",
        "            simplices.add(tuple(v[0]))\n",
        "        \n",
        "        laplacian_0 = np.matmul(boundary_operator(simplices, 1).toarray(), np.transpose(boundary_operator(simplices, 1).toarray()))\n",
        "        laplacian_1 = np.matmul(boundary_operator(simplices, 2).toarray(), np.transpose(boundary_operator(simplices, 2).toarray())) + np.matmul(np.transpose(boundary_operator(simplices, 1).toarray()), boundary_operator(simplices, 1).toarray())     \n",
        "        #laplacian_2 = np.matmul(boundary_operator(simplices, 3).toarray(), np.transpose(boundary_operator(simplices, 3).toarray())) + np.matmul(np.transpose(boundary_operator(simplices, 2).toarray()), boundary_operator(simplices, 2).toarray())\n",
        "\n",
        "        \n",
        "        # Attributes for Laplacian Dim(0) for each filtration value\n",
        "        eigval_0, eigvec_0 = np.linalg.eigh(laplacian_0)\n",
        "        eigval_0 = [0 if i <1e-3 else i for i in eigval_0]\n",
        "        b_0 = [j for j in eigval_0 if j==0]\n",
        "        b_0_positive = [j for j in eigval_0 if j>0]  \n",
        "        b_0_positive_rp = np.reciprocal(b_0_positive)\n",
        "        A_0 = len(b_0_positive)\n",
        "        ab_std_0 = np.absolute(eigval_0-np.average(eigval_0))\n",
        "    \n",
        "        beta_0 = len(b_0) #Attribute1\n",
        "        mean_0 = np.average(eigval_0) #Attribute2\n",
        "        std_0 = np.std(eigval_0) #Attribute3\n",
        "        sum_0 = np.sum(eigval_0) #Attribute4\n",
        "        min_0 = 0 if np.shape(b_0_positive)==(0,) else np.min(b_0_positive) #Attribute5 np.min(b_0_positive_formin)\n",
        "        max_0 = np.max(eigval_0) #Attribute6\n",
        "        ab_std_sum_0 = np.sum(ab_std_0) #Attribute7\n",
        "        order_2_sum_0 = np.sum(np.square(eigval_0)) #Attribute8\n",
        "        qwi_0 = np.sum(np.multiply(b_0_positive_rp,(A_0+1))) #Attribute9\n",
        "        #stn_0 = np.log(np.multiply(np.prod(b_0_positive),1/(A_0+1))) #Attribute10 This gives inf values\n",
        "        stn_0 = np.sum(np.log(b_0_positive)) - np.log(A_0+1) #Attribute10\n",
        "\n",
        "        \n",
        "        # Attributes for Laplacian Dim(1) for each filtration value\n",
        "        eigval_1, eigvec_1 = np.linalg.eigh(laplacian_1)\n",
        "        eigval_1 = [0 if i <1e-3 else i for i in eigval_1]\n",
        "        b_1 = [j for j in eigval_1 if j==0]\n",
        "        b_1_positive = [j for j in eigval_1 if j>0]\n",
        "        b_1_positive_rp = np.reciprocal(b_1_positive)\n",
        "        A_1 = len(b_1_positive)\n",
        "        ab_std_1 = np.absolute(eigval_1-np.average(eigval_1))\n",
        "\n",
        "        beta_1 = len(b_1) #Attribute1\n",
        "        mean_1 = 0 if np.shape(laplacian_1)==(0,0) else np.average(eigval_1) #Attribute2\n",
        "        std_1 = 0 if np.shape(laplacian_1)==(0,0) else np.std(eigval_1) #Attribute3\n",
        "        sum_1 = 0 if np.shape(laplacian_1)==(0,0) else np.sum(eigval_1) #Attribute4\n",
        "        min_1 = 0 if np.shape(laplacian_1)==(0,0) else np.amin(eigval_1) #Attribute5\n",
        "        max_1 = 0 if np.shape(laplacian_1)==(0,0) else np.amax(eigval_1) #Attribute6\n",
        "        ab_std_sum_1 = np.sum(ab_std_1) #Attribute7\n",
        "        order_2_sum_1 = np.sum(np.square(eigval_1)) #Attribute8\n",
        "        qwi_1 = np.sum(np.multiply(b_1_positive_rp,(A_1+1))) #Attribute9\n",
        "        #stn_1 = np.log(np.multiply(np.prod(b_1_positive),1/(A_1+1))) #Attribute10 This gives inf values\n",
        "        stn_1 = np.sum(np.log(b_1_positive)) - np.log(A_1+1) #Attribute10\n",
        "        \n",
        "        \n",
        "        vec.extend([beta_0,beta_1,std_0,std_1,sum_0,sum_1,min_0,min_1,max_0,max_1,mean_0,mean_1,ab_std_sum_0,ab_std_sum_1,order_2_sum_0,order_2_sum_1,qwi_0,qwi_1,stn_0,stn_1])\n",
        "             \n",
        "    veca.append(vec)    \n",
        "    "
      ],
      "metadata": {
        "id": "Zb1QfBgwKAne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data=veca)\n",
        "df.to_csv('last2filtration.csv', index=False, header=False)\n",
        "df"
      ],
      "metadata": {
        "id": "gP00q6vPz0UZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}